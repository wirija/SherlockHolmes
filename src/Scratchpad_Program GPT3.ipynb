{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip install chromadb\n",
    "# %pip install -U langchain langchainhub openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Initialise GenAI call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GenAI Variables and models\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = 'sk-xxx'\n",
    "VERTEX_API_KEY = \"xxx\"\n",
    "\n",
    "OPENAI_MODEL_VISION_PREVIEW = 'gpt-4-1106-vision-preview'\n",
    "OPENAI_MODEL_GPT3 = 'gpt-3.5-turbo-0125'\n",
    "\n",
    "VERTEX_MODEL_GEMINI = 'gemini-1.0-pro'\n",
    "VERTEX_MODEL_GEMINI_VISION = 'gemini-1.0-pro-vision'\n",
    "\n",
    "VERTEX_MODEL_ANTROPIC_HAIKU = 'claude-3-haiku@20240307'\n",
    "VERTEX_MODEL_ANTROPIC_SONNET = 'claude-3-sonnet@20240229'\n",
    "VERTEX_MODEL_MISTRAL = 'mistralai/Mixtral-8x7B-v0.1'\n",
    "OPENAI_EMBEDDING_3_LARGE = 'text-embedding-3-large'\n",
    "OPENAI_EMBEDDING_3_SMALL = 'text-embedding-3-small'\n",
    "OPENAI_EMBEDDING_ADA_002 = 'text-embedding-ada-002'\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_file (dir:str, filter):\n",
    "    return [os.path.join(root, file)  for root, dirs, files in os.walk(dir) for file in files if filter in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilise ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_fn = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'), model_name=OPENAI_EMBEDDING_ADA_002)\n",
    "# embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "\n",
    "class Collections:\n",
    "    Name: str\n",
    "    Documents: list\n",
    "    Metadatas: list\n",
    "    Ids: list\n",
    "    count_items: int\n",
    "\n",
    "    def __init__ (self, Name, Documents, Metadatas, Ids):\n",
    "        if ( \n",
    "            len(Documents) != len (Ids) &\n",
    "            len(Metadatas) != len(Documents)\n",
    "        ):\n",
    "            raise Exception(\"Error: Length of parameters do not match\")\n",
    "        \n",
    "        self.Name = Name\n",
    "        self.Documents = Documents\n",
    "        self.Metadatas = Metadatas\n",
    "        self.Ids = Ids\n",
    "        self.count_items = len(Ids)\n",
    "\n",
    "    def get_count(self):return self.count_items\n",
    "    def get_Documents(self): return self.Documents\n",
    "    def get_Metadatas(self): return self.Metadatas\n",
    "    def get_Ids(self): return self.Ids\n",
    "    def get_Name(self): return self.Name\n",
    "\n",
    "\n",
    "class Document_vdb:\n",
    "    vdb: chromadb\n",
    "    collections: Collections\n",
    "\n",
    "    def __init__ (\n",
    "            self, \n",
    "            vdb = None, \n",
    "            collections = None, \n",
    "            persistent_dir = None\n",
    "        ):\n",
    "        if vdb == None:\n",
    "            if persistent_dir == None:\n",
    "                self.vdb = chromadb.Client()\n",
    "            else:\n",
    "                self.vdb = chromadb.PersistentClient(path = persistent_dir)\n",
    "        else:\n",
    "            self.vdb = vdb\n",
    "        \n",
    "        if collections != None:\n",
    "            self.set_collections(collections)\n",
    "        else: self.collections = None\n",
    "\n",
    "    def get_vdb (self):\n",
    "        return self.vdb\n",
    "    \n",
    "    def get_collection(\n",
    "            self, \n",
    "            collection_name:str\n",
    "        ):\n",
    "        return self.vdb.get_collection(name = collection_name )\n",
    "\n",
    "    def set_collections(\n",
    "            self, \n",
    "            collections:Collections, \n",
    "            emb_fn = None\n",
    "        ):\n",
    "\n",
    "        if emb_fn == None: emb_fn = embedding_fn\n",
    "        count_items = collections.get_count()\n",
    "\n",
    "        collection = self.vdb.get_or_create_collection(\n",
    "            name=collections.get_Name(), \n",
    "            embedding_function=emb_fn \n",
    "        )\n",
    "        \n",
    "        Documents = collections.get_Documents()\n",
    "        Metadatas = collections.get_Metadatas()\n",
    "        Ids = collections.get_Ids()\n",
    "\n",
    "        for i in range(0, count_items):\n",
    "            collection.add( \n",
    "                documents = Documents[i],\n",
    "                metadatas = Metadatas[i],\n",
    "                ids = Ids[i]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "import hashlib\n",
    "import uuid \n",
    "import pypdf\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "text_splitter_token = TokenTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "def create_collections_dir (dir, collection_name) -> Collections:\n",
    "    files = list_file(dir, \".pdf\")\n",
    "    Metadatas = []\n",
    "    Ids = []\n",
    "    Documents = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            hash = str(hashlib.md5(f.read()).hexdigest())\n",
    "\n",
    "        pdfFileObject = open(file, 'rb')\n",
    "        pdfReader = pypdf.PdfReader(pdfFileObject)\n",
    "        count = len(pdfReader.pages)\n",
    "\n",
    "        for i in range(count):\n",
    "            metadata = {\n",
    "                'source': file,\n",
    "                'page': i,\n",
    "                'source_hash': hash,\n",
    "            }\n",
    "            page_chunks = text_splitter.split_text (pdfReader.pages[i].extract_text())\n",
    "            for page_chunk in page_chunks:\n",
    "                Ids.append(uuid.uuid1().hex)\n",
    "                Documents.append(page_chunk)\n",
    "                Metadatas.append(metadata)\n",
    "\n",
    "    return Collections(\n",
    "        Name = collection_name ,\n",
    "        Documents=Documents,\n",
    "        Metadatas=Metadatas,\n",
    "        Ids=Ids\n",
    "    )\n",
    "\n",
    "\n",
    "def create_collection_token (file, collection_name) -> Collections:\n",
    "    Metadatas = []\n",
    "    Ids = []\n",
    "    Documents = []\n",
    "\n",
    "    with open(file, 'rb') as f:\n",
    "        hash = str(hashlib.md5(f.read()).hexdigest())\n",
    "\n",
    "    pdfFileObject = open(file, 'rb')\n",
    "    pdfReader = pypdf.PdfReader(pdfFileObject)\n",
    "    count = len(pdfReader.pages)\n",
    "\n",
    "    for i in range(count):\n",
    "        metadata = {\n",
    "            'source': file,\n",
    "            'page': i,\n",
    "            'source_hash': hash,\n",
    "        }\n",
    "        page_chunks = text_splitter_token.split_text (pdfReader.pages[i].extract_text())\n",
    "        for page_chunk in page_chunks:\n",
    "            Ids.append(uuid.uuid1().hex)\n",
    "            Documents.append(page_chunk)\n",
    "            Metadatas.append(metadata)\n",
    "\n",
    "    return Collections(\n",
    "        Name = collection_name ,\n",
    "        Documents=Documents,\n",
    "        Metadatas=Metadatas,\n",
    "        Ids=Ids\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def create_collection_char (file, collection_name) -> Collections:\n",
    "    Metadatas = []\n",
    "    Ids = []\n",
    "    Documents = []\n",
    "\n",
    "    with open(file, 'rb') as f:\n",
    "        hash = str(hashlib.md5(f.read()).hexdigest())\n",
    "\n",
    "    pdfFileObject = open(file, 'rb')\n",
    "    pdfReader = pypdf.PdfReader(pdfFileObject)\n",
    "    count = len(pdfReader.pages)\n",
    "\n",
    "    for i in range(count):\n",
    "        metadata = {\n",
    "            'source': file,\n",
    "            'page': i,\n",
    "            'source_hash': hash,\n",
    "        }\n",
    "        page_chunks = text_splitter.split_text (pdfReader.pages[i].extract_text())\n",
    "        for page_chunk in page_chunks:\n",
    "            Ids.append(uuid.uuid1().hex)\n",
    "            Documents.append(page_chunk)\n",
    "            Metadatas.append(metadata)\n",
    "\n",
    "    return Collections(\n",
    "        Name = collection_name ,\n",
    "        Documents=Documents,\n",
    "        Metadatas=Metadatas,\n",
    "        Ids=Ids\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# dir = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling'\n",
    "# persist_dir = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_token'\n",
    "# collection_name = \"Tan_Hooi_Ling\"\n",
    "# files = list_file( dir, \".pdf\")\n",
    "# no_files = len(files)\n",
    "# i = 1\n",
    "\n",
    "# for file in files:\n",
    "#     print (f\"===== Processing file {i} / {no_files} -- {file}\")\n",
    "#     FS_collection  = create_collection_token(file, collection_name=f\"{collection_name}_{i}\")\n",
    "#     test = Document_vdb(collections= FS_collection, persistent_dir= persist_dir)\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# dir = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling'\n",
    "# persist_dir_char = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_char'\n",
    "# collection_name = \"Tan_Hooi_Ling\"\n",
    "# files = list_file( dir, \".pdf\")\n",
    "# no_files = len(files)\n",
    "# i = 1\n",
    "\n",
    "# for file in files:\n",
    "#     print (f\"===== Processing file {i} / {no_files} -- {file}\")\n",
    "#     FS_collection  = create_collection_char(file, collection_name=f\"{collection_name}_{i}\")\n",
    "#     test = Document_vdb(collections= FS_collection, persistent_dir= persist_dir_char)\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising Tan Hooi Ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tan_Hooi_Ling_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterwirija/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of requested results 20 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ END OF COLLECTION 1 =================\n",
      "Tan_Hooi_Ling_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ END OF COLLECTION 1 =================\n",
      "Tan_Hooi_Ling_2\n",
      "================ END OF COLLECTION 1 =================\n",
      "Tan_Hooi_Ling_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ END OF COLLECTION 1 =================\n",
      "Tan_Hooi_Ling_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ END OF COLLECTION 1 =================\n",
      "Tan_Hooi_Ling_6\n",
      "================ END OF COLLECTION 1 =================\n"
     ]
    }
   ],
   "source": [
    "persist_dir_char = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_char'\n",
    "persist_dir_token = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_token'\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "# OpenAIEmbeddings = OpenAIEmbeddings(api_key=os.environ.get('OPENAI_API_KEY'), model_name=OPENAI_EMBEDDING_ADA_002)\n",
    "persist_dir = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_token'\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=OPENAI_MODEL_GPT3 , temperature=0)\n",
    "\n",
    "client = chromadb.PersistentClient(path=persist_dir_char)  # or HttpClient()\n",
    "collections = client.list_collections()\n",
    "llm_results = []\n",
    "customer_name = \"Tan Hooi Ling\"\n",
    "\n",
    "for collection in collections:\n",
    "    print (collection.name)\n",
    "\n",
    "\n",
    "    vectordb = Chroma(persist_directory=persist_dir, collection_name = collection.name, embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "    retriever = vectordb.as_retriever( search_type=\"mmr\" , search_kwargs={\"k\": 5, \"include_metadata\": True})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    retriever_from_llm = MultiQueryRetriever.from_llm( retriever=retriever, llm=llm)\n",
    "\n",
    "\n",
    "    question = \"\"\"\n",
    "\n",
    "        Assume the role of a research assistant researching the biography of a person. Your current target is {customer_name}.\n",
    "        You are to review the content in the text below. \n",
    "\n",
    "        Task: Review a document about {customer_name} and identify key biographical facts:\n",
    "\n",
    "        1) Early Life:\n",
    "            1a) Birthplace & Date\n",
    "            1b) Hometown\n",
    "            1c) Siblings (number)\n",
    "        2) Education:\n",
    "            2a) Schools attended (names & locations)\n",
    "            2b) Degrees/Courses studied\n",
    "            2c) Dates of attendance\n",
    "        3) Career:\n",
    "            3a) Employers & Positions\n",
    "            3b) Employment Dates (start date and end date)\n",
    "\n",
    "\n",
    "        Output:\n",
    "         - Output will be markdown format.\n",
    "         - Each of the 3 section will be a # Heading level 1\n",
    "         - Refer to the output template in markdown format below\n",
    "\n",
    "        <Output Template> \n",
    "        # Summary of {customer_name}\n",
    "        <Place the summary of {Customer_Name} here>\n",
    "\n",
    "        # Early Life       \n",
    "        <place the {Customer_Name} early Life here in text>\n",
    "\n",
    "        # Education \n",
    "        Output the Education background result in the following markdown format\n",
    "        | School Name | Location | Course name | Degree type | Start Year | Graduation Year |\n",
    "        |---|---|---|---|---|---|\n",
    "        \n",
    "        # Career \n",
    "        Output the career result in the following markdown format\n",
    "        | Employer Name | Location | Job title | Start Year | End Year |\n",
    "        |---|---|---|---|---|\n",
    "\n",
    "        End year = refers to when the person is no longer part of the company\n",
    "\n",
    "\n",
    "        contrainst:    \n",
    "            Where you are unable to find the information, state them as \"Not Available\"\n",
    "        \"\"\"\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "    # unique_docs = retriever_from_llm.from_llm(query=question)\n",
    "    result = qa_chain({\"query\": question})\n",
    "\n",
    "    llm_results.append (result['result'])\n",
    "\n",
    "    print (\"================ END OF COLLECTION 1 =================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_results = \"\\n\\n\\n\".join ([text for text in llm_results])\n",
    "\n",
    "\n",
    "prompt_combine_result= rf\"\"\"\n",
    "    You are summarising a set of result from LLM retrieval. The topic is the biography you like to write include {customer_name} early Life, Education, and Career\n",
    "    Each result of the LLM is separated by three blank lines (\\n\\n\\n).\n",
    "    The documents were originally formatted in Markdown.and structured in the following manner \n",
    "    \n",
    "    <RESULT STRUCTURE> \n",
    "    # Summary of document\n",
    "    Place the summary of the document here\n",
    "    \n",
    "    # Summary of {customer_name}\n",
    "    <Place a comprehensive summary of {customer_name} here>\n",
    "\n",
    "    # Early Life       \n",
    "    <place the {customer_name} early Life here in text>\n",
    "\n",
    "    # Education \n",
    "    Output the Education background result in the following markdown format\n",
    "    | School Name | Location | Course name | Degree type | Start Year | Graduation Year |\n",
    "    |---|---|---|---|---|---|\n",
    "    \n",
    "    # Career \n",
    "    Output the career result in the following markdown format\n",
    "    | Employer Name | Location | Job title | Start Year | End Year |\n",
    "    |---|---|---|---|---|\n",
    "    \n",
    "    Sort the table by Employer Name\n",
    "\n",
    "    The following contraints are only for Start Year and End Year Columns:\n",
    "    - Start Year = Year of start of employment. Only output the year without month or day. Where Start Year is \"Not Available\" replace it with a 0. Where Start Year is \"present\" or \"current\", replace it with the current year\n",
    "    - End Year = Year of end of employment. Only output the year without month or day. Where End Year is \"Not Available\" replace it with 0. Where End Year is \"present\" or \"current\", Replace it with the current year\n",
    "\n",
    "\n",
    "    Task: \n",
    "    review the text between <RESULTS> and <\\RESULTS>. \n",
    "    Combine the information for each section \n",
    "        - # Summary of {customer_name}\n",
    "        - # Early Life  \n",
    "        - # Education \n",
    "        - # Career \n",
    "\n",
    "    <RESULTS>\n",
    "     {combined_results}\n",
    "    <\\RESULTS>\n",
    "\n",
    "    contrainst:\n",
    "        Ensure that # Summary of {customer_name} is comprehensive\n",
    "        The output should retain the same structure in each section\n",
    "        Do not review results that are \"No information found!!\"\n",
    "        Do not include <RESULTS> or <\\RESULTS> in the output\n",
    "        Replace all \"Not Available\" with a 0\n",
    "\"\"\"\n",
    "\n",
    "result_summary = llm.invoke(prompt_combine_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary of Tan Hooi Ling\n",
      "Tan Hooi Ling is a Malaysian businesswoman based in Singapore, best known as the co-founder and Chief Operating Officer (COO) of Grab Holdings Inc. She has been a key figure in leading the company's technology and corporate strategy teams.\n",
      "\n",
      "# Early Life\n",
      "- **Birthplace & Date:** Not Available\n",
      "- **Hometown:** Kuala Lumpur, Malaysia\n",
      "- **Siblings (number):** One older brother\n",
      "\n",
      "# Education\n",
      "| School Name | Location | Course name | Degree type | Start Year | Graduation Year |\n",
      "|---|---|---|---|---|---|\n",
      "| University of Bath | United Kingdom | Mechanical Engineering | Bachelor's Degree | 0 | 2006 |\n",
      "| Harvard Business School | United States | Business Administration | Master of Business Administration | 0 | 2011 |\n",
      "\n",
      "# Career\n",
      "| Employer Name | Location | Job title | Start Year | End Year |\n",
      "|---|---|---|---|---|\n",
      "| McKinsey & Company | Malaysia | Business Analyst | 0 | 0 |\n",
      "| Salesforce | San Francisco | Not Available | 0 | 0 |\n",
      "| Grab Holdings Inc. | Singapore | Chief Operating Officer | 2015 | 2023 |\n"
     ]
    }
   ],
   "source": [
    "print (result_summary.content)\n",
    "\n",
    "# REPLACING NOT AVAIALBLE WITH 0 - RESULT SHOWS THAT THIS IS CASE SENSTIVE IN GPT3.5, but GPT4 is more likely to understand the meaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Tan Hooi Ling\n",
    "Tan Hooi Ling is a Malaysian businesswoman based in Singapore, best known as the co-founder and Chief Operating Officer (COO) of Grab Holdings Inc. She is stepping down from her operational roles in 2023 after leading the company's technology and corporate strategy teams. Tan Hooi Ling is known for her humble and hardworking nature.\n",
    "\n",
    "# Early Life\n",
    "- Birthplace & Date: Kuala Lumpur, Malaysia\n",
    "- Hometown: Petaling Jaya, Malaysia\n",
    "- Siblings: One older brother\n",
    "\n",
    "# Education\n",
    "| School Name | Location | Course name | Degree type | Start Year | End Year |\n",
    "|---|---|---|---|---|---|\n",
    "| University of Bath | United Kingdom | Mechanical Engineering | Bachelor's degree | 2006 | Not Available |\n",
    "| Harvard Business School | United States | Business Administration | Master of Business Administration | 2011 | Not Available |\n",
    "\n",
    "# Career\n",
    "| Employer Name | Location | Job title | Start Year | End Year |\n",
    "|---|---|---|---|---|\n",
    "| McKinsey & Company | Malaysia | Business Analyst | Not Available | Not Available |\n",
    "| Salesforce | San Francisco | Not Available | Not Available | Not Available |\n",
    "| Grab Holdings Inc. | Singapore | Chief Operating Officer | 2015 | 2023 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def MD_to_df (text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    header = lines[1].strip(\"|\").split(\"|\")\n",
    "\n",
    "    data = [] \n",
    "\n",
    "    # Loop through lines starting from 2\n",
    "    for line in lines[3:]:\n",
    "        \n",
    "        # Break once we hit an empty line\n",
    "        if not line.strip():\n",
    "            break\n",
    "            \n",
    "        cols = line.strip(\"|\").split(\"|\")\n",
    "        row = dict(zip(header, cols))\n",
    "        data.append(row)\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Employer Name | Location | Job title | Start Year | End Year |\n",
      "|---|---|---|---|---|\n",
      "| McKinsey & Company | Malaysia | Business Analyst | 0 | 0 |\n",
      "| Salesforce | San Francisco | Not Available | 0 | 0 |\n",
      "| Grab Holdings Inc. | Singapore | Chief Operating Officer | 2015 | 2023 |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employer Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job title</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>End Year</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Grab Holdings Inc.</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Employer Name         Location                  Job title   \\\n",
       "0    McKinsey & Company         Malaysia           Business Analyst    \n",
       "1            Salesforce    San Francisco              Not Available    \n",
       "2    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "3    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "4    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "5    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "6    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "7    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "8    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "9    Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "10   Grab Holdings Inc.        Singapore    Chief Operating Officer    \n",
       "\n",
       "     Start Year    End Year     year  \n",
       "0              0           0     0.0  \n",
       "1              0           0     0.0  \n",
       "2           2015        2023  2015.0  \n",
       "3           2015        2023  2016.0  \n",
       "4           2015        2023  2017.0  \n",
       "5           2015        2023  2018.0  \n",
       "6           2015        2023  2019.0  \n",
       "7           2015        2023  2020.0  \n",
       "8           2015        2023  2021.0  \n",
       "9           2015        2023  2022.0  \n",
       "10          2015        2023  2023.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "result_string = str(result_summary.content)\n",
    "results_content = result_string[result_string.find(\"# Career\") + 8:]\n",
    "\n",
    "print (results_content)\n",
    "\n",
    "employment_history =  MD_to_df (results_content)\n",
    "\n",
    "\n",
    "employment_history[' Start Year '] = employment_history[' Start Year '].astype(int)\n",
    "employment_history[' End Year '] = employment_history[' End Year '].astype(int) \n",
    "\n",
    "employment_history = employment_history.astype({' Start Year ':'int64', ' End Year ':'int64'})\n",
    "\n",
    "for i, years in employment_history.apply(\n",
    "    lambda x: range(\n",
    "        min(x[' Start Year '], x[' End Year ']),\n",
    "        max(x[' Start Year '], x[' End Year ']) + 1\n",
    "    ),\n",
    "    axis='columns'\n",
    ").items():\n",
    "    for year in years:\n",
    "        new_index = len(employment_history.index)\n",
    "        employment_history.loc[new_index] = employment_history.loc[i].values\n",
    "        employment_history.loc[new_index, 'year'] = int(year)\n",
    "\n",
    "employment_history = employment_history.dropna().reset_index()\n",
    "\n",
    "\n",
    "# employment_history.loc[(employment_history[' Start Year '] == 0) & (employment_history[' End Year '] != 0) & (employment_history['year'] != 0) ]\n",
    "employment_history.drop(employment_history.loc[(employment_history[' Start Year '] == 0) & (employment_history[' End Year '] != 0) & (employment_history['year'] != 0) ].index, inplace=True)\n",
    "employment_history.drop(employment_history.loc[(employment_history[' Start Year '] != 0) & (employment_history[' End Year '] == 0) & (employment_history['year'] != 0) ].index, inplace=True)\n",
    "employment_history.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at McKinsey & Company in Malaysia for the year 0 does not have any specific income information available in the provided text. It is unclear if Tan Hooi Ling received any salary, bonuses, shares, or benefits during this time. The text primarily focuses on her role as the co-founder and chief operating officer of Grab, a start-up she founded in 2012. Therefore, it is not possible to provide detailed income information for her employment at McKinsey & Company in Malaysia for the year 0 based on the text provided. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. Unfortunately, specific details about her salary, bonus, shares, and benefits received during her time at this employment are not available in the provided text. Tan Hooi Ling is known to be media-shy and prefers to stay low-key, focusing on getting work done and spending time out of the news. She is described as introverted by nature and practical in her choices, such as selecting food stalls with short queues. Despite the lack of specific income information, it is evident that Tan Hooi Ling played a significant role in the growth and success of Grab, a company she co-founded.\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "|---------------|----------|-----------|------|-----------------------|----------------------|--------|----------------------------------|-----------|\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, based on the provided text, there is no specific information regarding her income, salary, bonuses, shares, or benefits received during her time at this employment. Therefore, the details of her financial compensation from this employment are not available. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific details about her salary, bonus, shares, and benefits from this employment are not available in the provided text. Therefore, it is not possible to determine her income from this particular job. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling joined management consultancy McKinsey & Company in Malaysia during the year 0. She did well enough for them to sponsor her to Harvard Business School, which was a life-changing opportunity for her. During her time at McKinsey & Company, she gained valuable experience in business decision-making and worked on projects in the region. Unfortunately, specific details about her salary, bonuses, shares, and other benefits received during her employment at McKinsey & Company in the year 0 are not available in the provided text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling took six months' leave from McKinsey to help launch Grab in KL. She then went back to San Francisco to serve out her bond, but kept in constant touch with the Grab team. After McKinsey, she worked at US tech company Salesforce and returned to join Grab full-time in April 2015. She currently oversees people operations and technology at Grab. Her husband, Mr. Tan, handles the commercial aspects, but their portfolios are interchangeable. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia during the year 0. Unfortunately, specific details about her salary, bonus, shares, and benefits are not available in the provided text. It seems that her role and contributions at McKinsey & Company were not the focus of the text provided.\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, based on the provided text, there is no specific information regarding her salary, bonus, shares, or other benefits received during her time at this employment. The text mainly focuses on her role at Grab and her thoughts on the platform's development. Therefore, the income details for her employment at McKinsey & Company remain unknown. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "|---------------|----------|----------|------|-----------------------|----------------------|-------|---------------------------------|-----------|\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was not employed by McKinsey & Company during the year 0. Therefore, no income information is available for this specific employment. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. Unfortunately, specific income information such as salary, bonus, shares, and benefits received during this time is not available in the provided text. Therefore, the details of Tan Hooi Ling's income from this employment are unknown. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by McKinsey & Company in Malaysia in the year 0. However, specific details about her salary, bonus, shares, and benefits received during this time are not available in the provided text. It is mentioned that Tan Hooi Ling has control-related rights under the Investment Agreement with Grab PH Holdings Inc. and also owns 50% of the voting shares in Jaya Grocer in Malaysia. Additionally, she has the ability to decide on business and financial strategies for Jaya Grocer. Further information regarding her income from this employment is not provided. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by McKinsey & Company in Malaysia, but specific income information such as salary, bonus, shares, and benefits received during the year 0 is not available in the provided text. It is mentioned that Tan Hooi Ling is a co-founder of Green Aurora Sdn Bhd, which is the Malaysian local partner of Jaya Grocer Holdings Sdn. Bhd. However, no specific income details are provided. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment details at McKinsey & Company for the year 0 are not provided in the text. Therefore, specific information regarding Tan Hooi Ling's income, salary, bonuses, shares, and benefits from this employment is not available. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Business Analyst | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked at McKinsey & Company as a Business Analyst from October 2006 to June 2009. During this time, her specific income details such as salary, bonus, shares, and benefits are not available in the provided text. Therefore, the exact financial compensation she received from this employment is not known. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Less than 1% of outstanding Ordinary Shares | Not Available | Tan Hooi Ling was employed by McKinsey & Company in Malaysia in the year 0. She held less than 1% of the outstanding Ordinary Shares in the company. Specific details about her salary, bonus, and other benefits are not available in the provided text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | 29,723,020 Class A Ordinary Shares | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. She received 29,723,020 Class A Ordinary Shares as part of her employment benefits. Specific details about her salary, bonus, and other benefits are not available in the provided text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. Unfortunately, specific income details such as salary, bonus, shares, and benefits received during this time are not available in the provided text.\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia during the year 0. However, specific details regarding salary, bonus, shares, and benefits received are not available in the provided text. Further information is needed to provide a comprehensive narrative of Tan Hooi Ling's employment at McKinsey & Company. |\n",
      "============== 0 ===============\n",
      "\n",
      "                | Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "                |---------------|----------|-----------|------|-----------------------|-----------------------|--------|----------------------------------|-----------|\n",
      "                | McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by McKinsey & Company in Malaysia during the year 0. However, based on the information provided in the text, there is no specific mention of Tan Hooi Ling's salary, bonus, shares, or other benefits received during this employment. Therefore, the details of Tan Hooi Ling's income from this employment are not available. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. Unfortunately, specific income information such as salary, bonus, shares, and benefits received during this time is not available in the provided text. Further details about Tan Hooi Ling's employment at McKinsey & Company are not provided in the text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific details regarding salary, bonus, shares, and benefits received during this time are not available in the provided text. It is possible that Tan Hooi Ling may have received some form of compensation such as salary, bonuses, shares, or benefits from this employment, but the exact details are not disclosed in the text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "|---------------|----------|----------|------|-----------------------|----------------------|--------|---------------------------------|-----------|\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was not employed by McKinsey & Company during the year 0. Therefore, no income information is available for this specific employment. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was not employed by McKinsey & Company during the year 0, therefore no income information is available for this specific employment. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at McKinsey & Company for the year 0 is not specified in the text provided. Therefore, salary, bonus, shares, and benefits received during this time are not available. Further information is needed to provide a comprehensive narrative of Tan Hooi Ling's employment at McKinsey & Company. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Business Analyst | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked as a Business Analyst at McKinsey & Company in Malaysia before co-founding Grab Holdings Inc. with Anthony Tan while attending Harvard Business School. She later moved to Singapore in 2014. During her time at McKinsey, she gained valuable experience in the business world which likely contributed to her success as a co-founder of Grab. Unfortunately, specific income details such as salary, bonuses, shares, and benefits received during her employment at McKinsey are not available in the provided text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked at McKinsey & Company in Malaysia, where she performed incredibly well and they sponsored her MBA education at Harvard Business School. During her time at McKinsey, she met her future co-founder of Grab, Anthony Tan. Unfortunately, specific details about her income, including salary, bonus, shares, and benefits, are not provided in the text. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling returned to McKinsey after graduation to serve out her bond with the consulting firm as a condition of sponsoring her education. She later moved on to Salesforce and took time out of her schedule to help with Grab in Southeast Asia. She returned to work full-time on Grab in 2015, taking on the title of COO and focusing on product, human resources, and customer experience. She announced her intention to step down by the end of 2023. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "|---------------|----------|----------|------|-----------------------|----------------------|-------|---------------------------------|-----------|\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at McKinsey & Company for the year 0 is not mentioned in the text provided. Therefore, specific income details such as salary, bonus, shares, and benefits are not available. It is unclear what role Tan Hooi Ling had at McKinsey & Company during this time period. Further information would be needed to provide a comprehensive narrative of Tan Hooi Ling's employment at McKinsey & Company in the year 0. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific income information such as salary, bonus, shares, and benefits received during this time is not available in the provided text. Therefore, the details of Tan Hooi Ling's income from this employment are not known. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, based on the provided text, there is no specific information available regarding Tan Hooi Ling's salary, bonus, shares, or other benefits received during this time. It seems that the text primarily focuses on the expiration of lock-up restrictions on certain shares held by key executives, including Tan Hooi Ling, rather than detailing her income from the employment. Therefore, the specific income details for Tan Hooi Ling in this context are not provided. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific details regarding salary, bonus, shares, and benefits received during this time are not available in the provided text. It is noted that Tan Hooi Ling held Class B Ordinary Shares in the company, but the exact value or income generated from these shares is not specified. Additional information is required to provide a comprehensive analysis of Tan Hooi Ling's income from this employment. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific details about her salary, bonus, shares, and benefits received during this time are not available in the provided text. Further information is needed to provide a comprehensive narrative of her employment at McKinsey & Company. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at McKinsey & Company in Malaysia in the year 0. However, specific details about salary, bonus, shares, and benefits received during this time are not available in the provided text. It is unclear what compensation Tan Hooi Ling received from this employment. |\n",
      "============== 0 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| McKinsey & Company | Malaysia | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by McKinsey & Company in Malaysia in the year 0. However, based on the provided text, there is no specific information regarding Tan Hooi Ling's salary, bonus, shares, or other benefits received during this employment. It is mentioned that Tan Hooi Ling used to be a co-founder of Jaya Grocer but no details on income are provided. Therefore, the specific income details for Tan Hooi Ling's employment at McKinsey & Company in Malaysia for the year 0 are not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "|---------------|----------|-----------|------|-----------------------|----------------------|--------|----------------------------------|-----------|\n",
      "| Salesforce    | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 does not provide any specific information regarding her salary, bonus, shares, or benefits. Therefore, it is not possible to determine her income from this employment based on the provided text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, specific income details such as salary, bonus, shares, and benefits are not available in the provided text. Tan Hooi Ling is known to be media-shy and prefers to stay behind the scenes, focusing on getting work done. She is described as practical and chooses stalls with short queues for meals. Despite the lack of income information, it is evident that Tan Hooi Ling plays a significant role in the company's operations. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 did not provide specific information on salary, bonus, shares, or benefits. The text only mentions her involvement with Grab and her actions during a lunch meeting. Therefore, her income details from this employment are not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, based on the provided text, there is no information available regarding her salary, bonus, shares, or other benefits received during her time at this employment. Therefore, it is not possible to provide specific details about her income from this particular job. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked at Salesforce in San Francisco in the year 0. However, specific income details such as salary, bonus, shares, and benefits are not available in the provided text. Tan Hooi Ling's career trajectory shifted towards understanding how businesses make decisions during this time. She previously worked at McKinsey & Company and attended Harvard Business School, which significantly impacted her life. She also had interactions with other Malaysians, including Mr. Anthony Tan, during her time at HBS. Overall, her experience at Salesforce likely contributed to her professional growth and development. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked at US tech company Salesforce during the year 0. The specific details of her income, including salary, bonuses, shares, and benefits, are not provided in the text. However, it is mentioned that she returned to join Grab full-time in April 2015 after working at Salesforce, indicating that her employment at Salesforce was a stepping stone in her career progression. She currently oversees people operations and technology at Grab. Her husband, Mr. Tan, handles the commercial aspects, and their portfolios are interchangeable. Tan Hooi Ling's time at Salesforce likely provided her with valuable experience and skills that she now applies in her role at Grab. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 did not provide specific information on salary, bonus, shares, or benefits. The text focused on her role at Grab and her experiences with the company over the past five years. Therefore, no income details were mentioned for her time at Salesforce in the provided text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 did not provide specific information regarding her salary, bonus, shares, or other benefits. Therefore, it is not possible to determine her income from this particular employment. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was not employed by Salesforce in the year 0, therefore no income information is available for this specific employment. |\n",
      "============== 1 ===============\n",
      "\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment | Narrative |\n",
      "|---------------|----------|-----------|------|-----------------------|----------------------|--------|---------------------------------|-----------|\n",
      "| 4             | Salesforce | San Francisco | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. Unfortunately, specific income information such as salary, bonus, shares, and benefits received during this time period is not available in the provided text.\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, specific details about salary, bonus, shares, and benefits received during this employment are not available in the provided text. Further information is needed to provide a comprehensive analysis of Tan Hooi Ling's income from this employment. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was not employed by Salesforce during the year 0. Therefore, no income information is available for this specific employment. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by Salesforce in San Francisco in the year 0. However, specific details about her salary, bonus, shares, and benefits received during her employment are not available in the provided text. It is recommended to refer to official documents or contact the company directly for accurate information. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling worked at Salesforce from February 2013 to March 2015, specializing in corporate strategy, corporate operations, pricing intelligence, and monetization. Unfortunately, specific income details such as salary, bonus, shares, and benefits for the year 0 are not available in the provided text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Less than 1% of outstanding Ordinary Shares | Not Available | Tan Hooi Ling was employed by Salesforce in San Francisco in the year 0. During this time, she received options to purchase Class B Ordinary Shares, restricted shares, and RSUs. She owned less than 1% of the outstanding Ordinary Shares and had options with various grant dates and expiration dates. Other details about her salary, bonus, and benefits are not available in the provided text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| 4 | Salesforce | San Francisco | 0 | Not Available | Not Available | 29,723,020 Class A Ordinary Shares | Not Available | Tan Hooi Ling was employed by 4 in San Francisco in the year 0. During this time, she received 29,723,020 Class A Ordinary Shares as part of her employment benefits. Information regarding her salary, bonus, and other benefits is not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| 4 | Salesforce | San Francisco | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. Unfortunately, specific income information such as salary, bonus, shares, and benefits received during this time period is not available in the provided text.\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 did not provide specific information on salary, bonus, shares, or benefits received. Therefore, the details of Tan Hooi Ling's income from this employment are not available in the provided text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed by Salesforce in San Francisco in the year 0. However, based on the provided text, there is no specific information regarding Tan Hooi Ling's salary, bonus, shares, or other benefits received during this employment. Therefore, the details of Tan Hooi Ling's income from this employment are not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| 4 | Salesforce | San Francisco | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. Unfortunately, specific information regarding her salary, bonus, shares, and benefits received during her time at this employment is not available in the provided text.\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, specific details about salary, bonus, shares, and benefits received during this time are not available in the provided text.\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| 4 | Salesforce | San Francisco | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, based on the provided text, there is no specific information available regarding her salary, bonus, shares, or other benefits received during her time of employment at this company. It is mentioned that she will be transitioning into an advisory role with Grab, so it is likely that she may not have received any income from this particular employment at Salesforce. Further details are not provided in the text. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 is mentioned in the text, but specific income details such as salary, bonus, shares, and benefits are not provided. It is stated that Tan Hooi Ling led Grab's technology organization and mentored technology leaders, but no specific financial information is given. Therefore, the income details for Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 are not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling was employed at Salesforce in San Francisco in the year 0. However, based on the provided text, there is no information available regarding Tan Hooi Ling's salary, bonus, shares, or other benefits received during this time. It appears that Tan Hooi Ling exited from operational roles at Grab and there is no mention of any income received from Salesforce in the text provided. Therefore, the specific details of Tan Hooi Ling's income from employment at Salesforce in the year 0 are not available. |\n",
      "============== 1 ===============\n",
      "| Employer Name | Location | Job Title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
      "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "| Salesforce | San Francisco | Not Available | 0 | Not Available | Not Available | Not Available | Not Available | Tan Hooi Ling's employment at Salesforce in San Francisco for the year 0 is not detailed in the provided text. Therefore, specific information regarding salary, bonus, shares, and benefits received during this time is not available.\n"
     ]
    }
   ],
   "source": [
    "persist_dir = r'/Users/peterwirija/Documents/GenAI/Data/Tan_Hooi_Ling/chromadb_THL_pages_token'\n",
    "\n",
    "llm = ChatOpenAI(model_name=OPENAI_MODEL_GPT3 , temperature=0)\n",
    "\n",
    "client = chromadb.PersistentClient(path=persist_dir_char)  # or HttpClient()\n",
    "collections = client.list_collections()\n",
    "llm_results = []\n",
    "combined_result = []\n",
    "\n",
    "for i in range(0, len(employment_history)):\n",
    "    for collection in collections:\n",
    "        # text = \"\\n\\n\\n\".join ([item for item in collection.get()['documents'] if \"hooi ling\".lower() in item.lower()])\n",
    "\n",
    "\n",
    "        for text in collection.get()['documents']:\n",
    "            if not(\"hooi ling\".lower() in text.lower()): continue\n",
    "            prompt_employment_SOW= rf\"\"\"\n",
    "                You are an analyst. Your job is to review the text between <START OF TEXT> and <END OF TEXT> below to identify  {customer_name}'s income.\n",
    "                Income is defined as any salary, shares, bonuses, and benefits. \n",
    "\n",
    "                {customer_name} has multiple employment. You are to gather information about a specific employment\n",
    "                    Employer: {employment_history.iloc[i,0]}\n",
    "                    Location: {employment_history.iloc[i,1]}\n",
    "                    Job Title: {employment_history.iloc[i,2]}\n",
    "                    Year of employment : {employment_history.iloc[i,5]}\n",
    "\n",
    "                <START OF TEXT>\n",
    "                {text}\n",
    "                <END OF TEXT>\n",
    "\n",
    "                Task: \n",
    "                    Review the between <START OF TEXT> and <END OF TEXT>\n",
    "                    Extract key income information that {customer_name} received during {customer_name} time in {employment_history.iloc[i,0]} for the year {employment_history.iloc[i,5]}. information should include\n",
    "                    - Salary\n",
    "                    - Shares\n",
    "                    - Bonuses\n",
    "                    - Other benefits\n",
    "                    Provide a narrative to {customer_name} employment in {employment_history.iloc[i,0]}\n",
    "\n",
    "                Output:\n",
    "                    Put the output in markdown format as per the following table:\n",
    "                    | Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
    "\n",
    "                    Markdown table Data dictionary:\n",
    "                    Employer Name =  Employer name\n",
    "                    Location =  location employer is located at\n",
    "                    Job Title = Job title at place of employment \n",
    "                    Year = Current Year under review\n",
    "                    Salary from employment  = Salary {customer_name} received for the year that {customer_name} was employed by employer\n",
    "                    Bonus from Employment = Bonus  {customer_name} received for the year that {customer_name} was employed by employer\n",
    "                    Shares = Shares  {customer_name} held in the company for the year\n",
    "                    Benefit from Employment = Benefits, other than Salary, Bonus and shares, receiverd by {customer_name} for the year that {customer_name} was employed by employer\n",
    "\n",
    "                contrainst:\n",
    "                    Ensure that Narrative column is comprehensive\n",
    "                    Do not make up information.\n",
    "                    Where information is not available state \"Not Available\"\n",
    "            \"\"\"\n",
    "\n",
    "            result = llm.invoke(prompt_employment_SOW)\n",
    "            # qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "            # # unique_docs = retriever_from_llm.from_llm(query=question)\n",
    "            # result = qa_chain({\"query\": prompt_employment_SOW})\n",
    "            combined_result.append (result.content)\n",
    "\n",
    "            print (rf\"============== {i} ===============\")\n",
    "            print (result.content)\n",
    "\n",
    "combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 55\u001b[0m\n\u001b[1;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model_name\u001b[38;5;241m=\u001b[39mOPENAI_MODEL_GPT4_0125 , temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m prompt_combine_result\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    You are summarising a set of result from LLM retrieval. The topic is the biography you like to write include \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcustomer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m early Employment \u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m    Each result of the LLM is separated by three blank lines (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn).\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m        Replace all \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Available\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with a 0\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 55\u001b[0m result_employment_SOW \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_combine_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_employment_SOW\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:154\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    150\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    151\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    153\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 154\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    163\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:554\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    548\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    552\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    553\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    414\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    416\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    417\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    419\u001b[0m ]\n\u001b[1;32m    420\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:405\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 405\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_core/language_models/chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 624\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/langchain_openai/chat_models/base.py:484\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    479\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    483\u001b[0m }\n\u001b[0;32m--> 484\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/openai/_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1212\u001b[0m     )\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/openai/_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/openai/_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    937\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/GenAI/.venv/lib/python3.8/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "combined_text = \"\\n\\n\\n\".join ([text for text in combined_result])\n",
    "\n",
    "OPENAI_MODEL_GPT4_0125 = 'gpt-4-0125-preview'\n",
    "\n",
    "llm = ChatOpenAI(model_name=OPENAI_MODEL_GPT4_0125 , temperature=0)\n",
    "\n",
    "prompt_combine_result= rf\"\"\"\n",
    "    You are summarising a set of result from LLM retrieval. The topic is the biography you like to write include {customer_name} early Employment \n",
    "    Each result of the LLM is separated by three blank lines (\\n\\n\\n).\n",
    "    The documents were originally formatted in Markdown.and structured in the following manner \n",
    "    \n",
    "    <RESULT STRUCTURE> \n",
    "    # Summary of document\n",
    "    Place the summary of the document here\n",
    "    \n",
    "    \n",
    "    # Career \n",
    "    Output the career result in the following markdown format\n",
    "    Put the output in markdown format as per the following table:\n",
    "    | Employer Name | Location | Job title | Year | Salary from Employment | Bonus from Employment | Shares | Benefit received from Employment  | Narrative |\n",
    "\n",
    "    Markdown table Data dictionary:\n",
    "    Employer Name =  Employer name\n",
    "    Location =  location employer is located at\n",
    "    Job Title = Job title at place of employment \n",
    "    Year = Current Year under review\n",
    "    Salary from employment  = Salary {customer_name} received for the year that {customer_name} was employed by employer\n",
    "    Bonus from Employment = Bonus  {customer_name} received for the year that {customer_name} was employed by employer\n",
    "    Shares = Shares  {customer_name} held in the company for the year\n",
    "    Benefit from Employment = Benefits, other than Salary, Bonus and shares, receiverd by {customer_name} for the year that {customer_name} was employed by employer\n",
    "    \n",
    "    Sort the table by Employer Name\n",
    "\n",
    "    The following contraints are only for Start Year and End Year Columns:\n",
    "    - Start Year = Year of start of employment. Only output the year without month or day. Where Start Year is \"Not Available\" replace it with a 0. Where Start Year is \"present\" or \"current\", replace it with the current year\n",
    "    - End Year = Year of end of employment. Only output the year without month or day. Where End Year is \"Not Available\" replace it with 0. Where End Year is \"present\" or \"current\", Replace it with the current year\n",
    "\n",
    "\n",
    "    Task: \n",
    "    review the text between <RESULTS> and <\\RESULTS>. \n",
    "    Combine the information into a single row where \"Employer Name\", \"Location\", \"Job Title\", and \"Year\" are the same \n",
    "\n",
    "    <RESULTS>\n",
    "     {combined_text}\n",
    "    <\\RESULTS>\n",
    "\n",
    "    contrainst:\n",
    "        Ensure that # Summary of {customer_name} is comprehensive\n",
    "        The output should retain the same structure in each section\n",
    "        Do not review results that are \"No information found!!\"\n",
    "        Do not include <RESULTS> or <\\RESULTS> in the output\n",
    "        Replace all \"Not Available\" with a 0\n",
    "\"\"\"\n",
    "\n",
    "result_employment_SOW = llm.invoke(prompt_combine_result)\n",
    "\n",
    "print(result_employment_SOW.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
